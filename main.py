import os
import sys
from contextlib import asynccontextmanager
from typing import List
from langchain_community.chat_models.tongyi import ChatTongyi
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from langchain.agents import create_agent  # æ ¸å¿ƒæ”¹å˜ï¼šä½¿ç”¨æ–°ç‰ˆå·¥å‚å‡½æ•°
from langchain_mcp_adapters.client import MultiServerMCPClient
from fastapi.middleware.cors import CORSMiddleware
from langchain_core.messages import HumanMessage, AIMessage

# --- é…ç½®éƒ¨åˆ† ---
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
MCP_SERVER_PATH = os.path.join(CURRENT_DIR, "MCP_SERVER.py")

# å…¨å±€å˜é‡
agent = None  
mcp_client = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    FastAPI ç”Ÿå‘½å‘¨æœŸï¼šåˆå§‹åŒ– MCP å®¢æˆ·ç«¯å’Œ Agent
    """
    global agent, mcp_client
    
    print(f"ğŸ”— Connecting to MCP Server: {MCP_SERVER_PATH}")
    
    # 1. åˆå§‹åŒ– MCP Client
    mcp_client = MultiServerMCPClient(
        {
            "campus_algorithm": {
                "transport": "stdio",
                "command": sys.executable,
                "args": [MCP_SERVER_PATH],
            }
        }
    )
    
    # 2. è·å–å·¥å…· (å¼‚æ­¥)
    tools = await mcp_client.get_tools()
    print(f"ğŸ› ï¸  Loaded Tools: {[t.name for t in tools]}")

    # 3. åˆå§‹åŒ–æ¨¡å‹
    model = ChatTongyi(model="qwen-flash", temperature=0)

    # 4. åˆ›å»º Agent (æ ¸å¿ƒæ”¹å˜)
    # create_agent å†…éƒ¨æ„å»ºäº† LangGraph è¿è¡Œæ—¶
    system_prompt = (
        "ä½ çš„åå­—å«é˜¿ç™½ï¼Œä½ æ˜¯ä¸€ä¸ªäº‘é›¾å±±æ™¯åŒºæ™ºæ…§å¯¼æ¸¸åŠ©æ‰‹ã€‚ä½ çš„æ ¸å¿ƒèƒ½åŠ›æ˜¯å¸®åŠ©è®¿å®¢è§„åˆ’è·¯çº¿å’Œä»‹ç»æ™¯ç‚¹ã€‚"
        "ä½ æœ‰ä»¥ä¸‹å‡ ä¸ªå¼ºå¤§çš„è·¯çº¿è§„åˆ’å·¥å…·ï¼Œè¯·æ ¹æ®ç”¨æˆ·æ„å›¾çµæ´»é€‰æ‹©ï¼š"
        "1. å¦‚æœç”¨æˆ·é—®Aåˆ°Bæ€ä¹ˆèµ°ï¼Œè°ƒç”¨ 'find_shortest_path'ã€‚"
        "2. å¦‚æœç”¨æˆ·æƒ³â€œé€›å®Œæ‰€æœ‰æ™¯ç‚¹â€ã€â€œå…¨å›¾æ‰“å¡â€æˆ–â€œéšæœºæ¸¸è§ˆâ€ï¼Œè°ƒç”¨ 'generate_all_spots_tour'ã€‚"
        "3. å¦‚æœç”¨æˆ·æƒ³â€œæ¨èè·¯çº¿â€ã€â€œé€‚åˆè€äººçš„â€ã€â€œåˆºæ¿€çš„â€ã€â€œæ‹œä½›çš„â€ï¼Œè°ƒç”¨ 'recommend_themed_route'ã€‚"
        "\n"
        "é‡è¦è¾“å‡ºè§„åˆ™ï¼šå¦‚æœå·¥å…·è¿”å›ç»“æœä¸­åŒ…å« 'path_codes' åˆ—è¡¨ï¼Œè¯·ä½ åŠ¡å¿…æ‰§è¡Œä»¥ä¸‹ä¸¤æ­¥ï¼š"
        "1. ç”¨äº²åˆ‡ã€å¯¼æ¸¸èˆ¬çš„å£å»å‘ç”¨æˆ·ä»‹ç»è¿™æ¡è·¯çº¿ï¼ˆå¼•ç”¨å·¥å…·è¿”å›çš„ description æˆ– reasonï¼‰ã€‚"
        "2. åœ¨å›å¤çš„ã€æœ€åä¸€è¡Œã€‘ï¼Œä¸”å¿…é¡»æ˜¯æœ€åä¸€è¡Œï¼Œè¾“å‡ºè·¯å¾„æ•°æ®ï¼Œæ ¼å¼ä¸¥æ ¼å¦‚ä¸‹ï¼š"
        "PATH_DATA: ['S01', 'S02', 'S05']"
        "(ä¸è¦æŠŠè¿™ä¸ªåˆ—è¡¨èå…¥åˆ°è‡ªç„¶è¯­è¨€å¥å­ä¸­ï¼Œå¿…é¡»å•ç‹¬å ä¸€è¡Œï¼Œä»¥ä¾¿å‰ç«¯åœ°å›¾ç»˜åˆ¶)"
    )
    
    agent = create_agent(
        model=model,
        tools=tools,
        system_prompt=system_prompt
    )
    
    print("ğŸ¤– Agent initialized successfully (Graph-based).")
    
    yield
    


app = FastAPI(title="Campus Guide Agent API", lifespan=lifespan)

# 1. é…ç½®è·¨åŸŸ (æ–°å¢ä»£ç )
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å…è®¸æ‰€æœ‰æ¥æºï¼Œç”Ÿäº§ç¯å¢ƒå»ºè®®æ”¹ä¸º ["http://localhost:5173"]
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
# --- API å®šä¹‰ ---

class ChatRequest(BaseModel):
    query: str
    # å¯é€‰ï¼šå¦‚æœä½ æƒ³åœ¨å‰ç«¯ä¿ç•™å†å²è®°å½•ï¼Œå¯ä»¥ä¼  messages æ•°ç»„è¿‡æ¥
    # history: List[dict] = [] 

class ChatResponse(BaseModel):
    response: str
    tool_used: bool = False # æ ‡è¯†æ˜¯å¦ä½¿ç”¨äº†å·¥å…·ï¼Œä¾¿äºå‰ç«¯åšç‰¹æ®Šæ¸²æŸ“

@app.post("/chat", response_model=ChatResponse)
async def chat_endpoint(request: ChatRequest):
    if not agent:
        raise HTTPException(status_code=503, detail="Agent not initialized")
    
    try:
        # 5. è°ƒç”¨ Agent
        # æ–°ç‰ˆ invoke æ¥æ”¶ {"messages": [...]}
        # è¿™é‡Œçš„ messages ä¼šè‡ªåŠ¨è¿½åŠ åˆ° Agent çš„çŠ¶æ€ä¸­
        input_message = HumanMessage(content=request.query)
        
        result = await agent.ainvoke({
            "messages": [input_message]
        })
        
        # 6. è§£æç»“æœ
        # result["messages"] åŒ…å«äº†å®Œæ•´çš„äº¤äº’å†å² (Human -> AI (tool_call) -> Tool -> AI)
        last_message = result["messages"][-1]
        
        # ç®€å•åˆ¤æ–­æ˜¯å¦ä½¿ç”¨äº†å·¥å…·ï¼ˆæ£€æŸ¥å†å²æ¶ˆæ¯ä¸­æ˜¯å¦æœ‰ ToolMessageï¼‰
        # ä¹Ÿå¯ä»¥æ£€æŸ¥ last_message.content æ˜¯å¦åŒ…å«ç‰¹å®šçš„ç»“æ„åŒ–æ•°æ®
        has_tool_call = any(msg.type == "tool" for msg in result["messages"])

        return ChatResponse(
            response=last_message.content,
            tool_used=has_tool_call
        )

    except Exception as e:
        print(f"Error during agent invocation: {e}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)